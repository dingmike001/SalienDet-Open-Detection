2023-01-08 19:53:21,367 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3070 Ti Laptop GPU
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.13.1
OpenCV: 4.6.0
MMCV: 1.6.1
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.25.0+266f1fa
------------------------------------------------------------

2023-01-08 19:53:29,353 - mmdet - INFO - Distributed training: False
2023-01-08 19:53:37,241 - mmdet - INFO - Config:
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=2)
model = dict(
    type='YOLOV3',
    backbone=dict(
        type='Darknet',
        depth=53,
        out_indices=(3, 4, 5),
        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),
    neck=dict(
        type='YOLOV3Neck',
        num_scales=3,
        in_channels=[1024, 512, 256],
        out_channels=[512, 256, 128]),
    bbox_head=dict(
        type='YOLOV3Head',
        num_classes=1,
        in_channels=[512, 256, 128],
        out_channels=[1024, 512, 256],
        anchor_generator=dict(
            type='YOLOAnchorGenerator',
            base_sizes=[[(116, 90), (156, 198), (373, 326)],
                        [(30, 61), (62, 45), (59, 119)],
                        [(10, 13), (16, 30), (33, 23)]],
            strides=[32, 16, 8]),
        bbox_coder=dict(type='YOLOBBoxCoder'),
        featmap_strides=[32, 16, 8],
        loss_cls=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            loss_weight=1.0,
            reduction='sum'),
        loss_conf=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            loss_weight=1.0,
            reduction='sum'),
        loss_xy=dict(
            type='CrossEntropyLoss',
            use_sigmoid=True,
            loss_weight=2.0,
            reduction='sum'),
        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),
    train_cfg=dict(
        assigner=dict(
            type='GridAssigner',
            pos_iou_thr=0.5,
            neg_iou_thr=0.5,
            min_pos_iou=0)),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        conf_thr=0.005,
        nms=dict(type='nms', iou_threshold=0.45),
        max_per_img=100))
dataset_type = 'CocoDataset'
classes = ('object', )
img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='LoadAnnotations',
        with_bbox=True,
        with_mask=False,
        poly2mask=False),
    dict(
        type='Resize',
        img_scale=(1333, 800),
        multiscale_mode='range',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Normalize',
        mean=[0, 0, 0],
        std=[255.0, 255.0, 255.0],
        to_rgb=True),
    dict(type='Pad', size=(750, 1333), pad_val=0),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Normalize',
                mean=[0, 0, 0],
                std=[255.0, 255.0, 255.0],
                to_rgb=True),
            dict(type='Pad', size=(750, 1333), pad_val=0),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        img_prefix='/home/mike/Documents/dataset/neu_scene/v10samples/train',
        classes=('object', ),
        ann_file=
        '/home/mike/Pycharm_Prj/neucen_kitti/meta_data/Tasks/1/train_obj_demo.json',
        type='CocoDataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='LoadAnnotations',
                with_bbox=True,
                with_mask=False,
                poly2mask=False),
            dict(
                type='Resize',
                img_scale=(1333, 800),
                multiscale_mode='range',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Normalize',
                mean=[0, 0, 0],
                std=[255.0, 255.0, 255.0],
                to_rgb=True),
            dict(type='Pad', size=(750, 1333), pad_val=0),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        img_prefix='/home/mike/Documents/dataset/neu_scene/v10samples/val',
        classes=('object', ),
        ann_file=
        '/home/mike/Pycharm_Prj/neucen_kitti/meta_data/Tasks/1/val_obj_demo.json',
        type='CocoDataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.0),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[255.0, 255.0, 255.0],
                        to_rgb=True),
                    dict(type='Pad', size=(750, 1333), pad_val=0),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        img_prefix='/home/mike/Documents/dataset/neu_scene/v10samples/val',
        classes=('object', ),
        ann_file=
        '/home/mike/Pycharm_Prj/neucen_kitti/meta_data/Tasks/1/val_obj_demo.json',
        type='CocoDataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.0),
                    dict(
                        type='Normalize',
                        mean=[0, 0, 0],
                        std=[255.0, 255.0, 255.0],
                        to_rgb=True),
                    dict(type='Pad', size=(750, 1333), pad_val=0),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=5)
optimizer = dict(type='Adam', lr=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(policy='fixed')
runner = dict(type='EpochBasedRunner', max_epochs=273)
work_dir = './work_dirs/neu_yolo_test'
auto_resume = False
gpu_ids = [0]

2023-01-08 19:53:37,242 - mmdet - INFO - Set random seed to 234543293, deterministic: False
2023-01-08 19:53:38,897 - mmdet - INFO - initialize Darknet with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://darknet53'}
Name of parameter - Initialization information

backbone.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.conv.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.conv.bn.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.conv.bn.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv1.conv.weight - torch.Size([32, 64, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv1.bn.weight - torch.Size([32]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv1.bn.bias - torch.Size([32]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv2.conv.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv2.bn.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block1.res0.conv2.bn.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.conv.conv.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.conv.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.conv.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv1.conv.weight - torch.Size([64, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv2.conv.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res0.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv1.conv.weight - torch.Size([64, 128, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv1.bn.weight - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv1.bn.bias - torch.Size([64]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv2.conv.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv2.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block2.res1.conv2.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.conv.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.conv.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.conv.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res0.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res1.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res2.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res3.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res4.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res5.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res6.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv1.conv.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv1.bn.weight - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv1.bn.bias - torch.Size([128]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv2.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block3.res7.conv2.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.conv.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.conv.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.conv.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res0.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res1.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res2.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res3.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res4.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res5.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res6.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv1.bn.weight - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv1.bn.bias - torch.Size([256]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv2.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block4.res7.conv2.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.conv.conv.weight - torch.Size([1024, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.conv.bn.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.conv.bn.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv2.conv.weight - torch.Size([1024, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv2.bn.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res0.conv2.bn.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv2.conv.weight - torch.Size([1024, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv2.bn.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res1.conv2.bn.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv2.conv.weight - torch.Size([1024, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv2.bn.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res2.conv2.bn.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv1.bn.weight - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv1.bn.bias - torch.Size([512]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv2.conv.weight - torch.Size([1024, 512, 3, 3]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv2.bn.weight - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

backbone.conv_res_block5.res3.conv2.bn.bias - torch.Size([1024]): 
PretrainedInit: load from open-mmlab://darknet53 

neck.detect1.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv2.conv.weight - torch.Size([1024, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect1.conv2.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv2.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv3.conv.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect1.conv3.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv3.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv4.conv.weight - torch.Size([1024, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect1.conv4.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv4.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv5.conv.weight - torch.Size([512, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect1.conv5.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect1.conv5.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.conv1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv1.conv.weight - torch.Size([256, 768, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect2.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv3.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect2.conv3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv4.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect2.conv4.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv4.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv5.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect2.conv5.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect2.conv5.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.conv2.conv.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv1.conv.weight - torch.Size([128, 384, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect3.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv2.conv.weight - torch.Size([256, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect3.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv3.conv.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect3.conv3.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv3.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv4.conv.weight - torch.Size([256, 128, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect3.conv4.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv4.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv5.conv.weight - torch.Size([128, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.detect3.conv5.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

neck.detect3.conv5.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.0.conv.weight - torch.Size([1024, 512, 3, 3]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_bridge.0.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.0.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.1.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_bridge.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.2.conv.weight - torch.Size([256, 128, 3, 3]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_bridge.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_bridge.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOV3  

bbox_head.convs_pred.0.weight - torch.Size([18, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_pred.0.bias - torch.Size([18]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_pred.1.weight - torch.Size([18, 512, 1, 1]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_pred.1.bias - torch.Size([18]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_pred.2.weight - torch.Size([18, 256, 1, 1]): 
Initialized by user-defined `init_weights` in YOLOV3Head  

bbox_head.convs_pred.2.bias - torch.Size([18]): 
Initialized by user-defined `init_weights` in YOLOV3Head  
2023-01-08 19:53:41,346 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2023-01-08 19:53:41,397 - mmdet - INFO - Start running, host: mike@mike-Alienware-m15-R7, work_dir: /home/mike/Pycharm_Prj/neu_scene_only_unknown_detector_1115/tools/work_dirs/neu_yolo_test
2023-01-08 19:53:41,398 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) FixedLrUpdaterHook                 
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) FixedLrUpdaterHook                 
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) FixedLrUpdaterHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-01-08 19:53:41,398 - mmdet - INFO - workflow: [('train', 1)], max: 273 epochs
2023-01-08 19:53:41,399 - mmdet - INFO - Checkpoints will be saved to /home/mike/Pycharm_Prj/neu_scene_only_unknown_detector_1115/tools/work_dirs/neu_yolo_test by HardDiskBackend.
